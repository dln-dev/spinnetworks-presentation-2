\begin{document}

\mode<presentation>{
\title{Spin Networks for Perfect State Transfer \\ Part II}
\author{dln-dev}
\titlegraphic{\includegraphics[width=3cm]{Images/switch_square}}
\date{16. November 2016}

\frame{\titlepage}
}

\mode<article>{
\begin{titlepage}
	\center
	\vspace*{5.0cm}
	{ \huge \bfseries Spin Networks for Perfect State Transfer \\ Part II}\\[0.4cm]

	\textsc{\Large dln-dev}\\[1.5cm]
	{\large 16. November 2016}\\[4.0cm]

	\includegraphics[width=0.3\textwidth]{Images/switch_square}\\[1cm]
	\vfill
\end{titlepage}

\tableofcontents
}

\section{Recap}
\subsection{Motivation}
\mode<presentation>{
\begin{frame}{Motivation}\label{Motivation}
	\begin{columns}[T]
		\begin{column}{0.5\textwidth}
			\centering
   			\begin{itemize}
				\item Connecting components of quantum computers
				\item Often: photons
				\item Best to use similar hardware
			\end{itemize}
		\end{column}
		\begin{column}{0.5\textwidth}
			\centering
   			Processors \\
   			\includegraphics[width=\textwidth/2]{Images/processor}\\
   			\cite{Kostak2007}
   			%\mycite{Kostak, Nikolopoulos und Jex, Phys. Rev. A 75 042319}%Mr. Smith, THE_JOURNAL {\bf 00}, 000000 (0000)}
		\end{column}
	\end{columns}
\end{frame}
}

\begin{center}
	\includeslide{Motivation}
\end{center}

\noindent Connecting components, photons, example: chines satellite, short distances: better similar hardware.


\subsection{Requirements}
\mode<presentation>{
\begin{frame}{Requirements}\label{Requirements}
	\begin{itemize}
		\item Separation of highly controlled regions
		\item Spacers
		\begin{itemize}
			\item (Perfect) state transfer
			\item Fixed interactions
			\item Natural dynamics
			\item Control single qubit at each end only
		\end{itemize}
	\end{itemize}
	
	$\rightarrow$ Spin networks!
\end{frame}
}

\begin{center}
	\includeslide{Requirements}
\end{center}

\noindent The aforementioned requirements suggest a medium similar to what quantum registers are made of. Thus, no conversion, e.g. from solid state registers to photons is necessary. We will restrict ourselves here to perfect state transfer, fixed interactions and natural dynamics. Control over these spacers is then reduced to initialization, initial state transfer (perhaps in the form of a SWAP gate operation) and processing of the received qubit. At each site, only a single qubit shall be controlled. Other options will be explored at a later time. \par
A natural suggestion for a realization would be networks of two-level systems comprising qubits themselves. Therefore, we will investigate the feasibility of spin networks as quantum state transfer enablers. This is called spin chain engineering.

\subsection{Model}
\mode<presentation>{
\begin{frame}[t]{Model}\label{Model}	
	\begin{exampleblock}{}
		\setlength\abovedisplayskip{-8pt}
		\begin{center}
			\[H_{XX}=\frac{1}{2}\sum_{i=1}^{N}{J_i\left[\sigma_i^x\sigma_{i+1}^x + \sigma_i^y\sigma_{i+1}^y\right]} + h_i\sigma_i^z \]
		\end{center}
	\end{exampleblock}

	\begin{itemize}
		\item $J_i\in \{-1,0,1\}$ (here)
		\item No z coupling
		\item $\left[H_{XX},\sigma^z_\text{tot}\right] = 0$
		\item $H_{XX}$ restricted to the single spin subspace is the adjacency matrix of the network
	\end{itemize}
\end{frame}
}

\begin{center}
	\includeslide{Model}
\end{center}

\noindent The model we are using is a reduced Heisenberg model. We assume x- and y-component interaction only and omit z-interaction completely for computability reasons. z-interactions do not pose problems in principal, since we will look at single spin excitations only for now. Further, we will assume homogeneous (same coupling between every qubit) and isotropic couplings (same coupling constant for x- and y-component respectively). This is called the XX-model. Other configurations are no principal hindrance, but these rather loose assumptions make an introduction to this topic much easier.\par
The total z-spin operator commutes with the hamiltonian. Therefore, a common set of eigenvectors exists. The hamiltonian consequently can be decomposed into several subspaces each belonging to a specific eigenvalue of the total z-spin operator. The dynamics of a state belonging to one such subspace will therefore stay in the specific subspace. A state belonging to the single spin subspace will evolve into a superposition of single spin states.\par
The eigenstates can be calculated by diagonalizing the hamiltonian or analyzing states on a ferromagnetic chain\cite{Stolze2014}. Low energetic spin waves are superpositions of all single spin up states (assuming periodic boundary conditions at the moment). Sharply localized single spin states can then be constructed as superpositions of these spin wave states. These are sometimes called twisted-w states in quantum information science\cite{Osborne2004}. 
%The term seems to stem from Fourier analysis of radio signals.


\mode<presentation>{
\begin{frame}[t]{Adjacency matrices}\label{AdjacencyMatrices}
	\begin{columns}[T]
		\begin{column}{0.5\textwidth}
			\centering
   			\includegraphics[trim=0 0 0 -5mm, width=\textwidth]{Images/chain3} \\
   			\includegraphics[trim=0 0 0 -25mm, width=0.7\textwidth]{Images/multispinex} \\
   			\includegraphics[trim=0 0 0 -15mm, width=\textwidth]{Images/chain6_perf}
		\end{column}
		\begin{column}{0.5\textwidth}
			\centering
			\includegraphics[trim=0 0 0 15mm, width=0.4\textwidth]{Images/adj_chain3} \\
    		\includegraphics[trim=0 0 0 -10mm, width=0.5\textwidth]{Images/adj_ring6_2} \\
    		\includegraphics[trim=0 0 0 -5mm, width=0.4\textwidth]{Images/adj_chain6_perf}
		\end{column}
	\end{columns}
\end{frame}
}

\begin{center}
	\includeslide{AdjacencyMatrices}
\end{center}

\noindent An algebraic treatment of graphs is made possible by adjacency matrices. These encode the edges of a graph by representing vertices as rows and columns. If there is a connection between qubit 1 and 2, there will be a 1 in row 1, second column or zero  otherwise. Edges are unordered sets and the adjacency matrix therefore is symmetric. The consequence of this is that there exists a set of orthogonal eigenvectors which will be important in a proof later on.\par
The examples here are the adjacency matrices of a 3-qubit chain and the 2-spin subspace representation graph of a 6-qubit ring.


%\mode<presentation>{\begin{frame}{Math setup}\label{Mathsetup}
%	\begin{description}
%	\item [Ground state of ferromagnetic spin-$\frac{1}{2}$ chain:] \[ \ket{\uparrow}_1 \otimes \ket{\uparrow}_2 \otimes \dots \otimes \ket{\uparrow}_N = \ket{\uparrow_1\uparrow_2\dots\uparrow_N} := \ket{0} \]
%	\item [Excitation operator $\sigma^- = \frac{1}{2}\left(\sigma^x - \text{i}\sigma^y\right)$:] \[ \text{1}_1 \otimes \text{1}_2 \otimes \dots \otimes \text{1}_{s-1} \otimes \sigma^- \otimes \text{1}_{s+1} \otimes \dots \otimes \text{1}_N := \sigma^-_s \]
%	\item [Single spin excitation:] \[ \sigma^-_s\ket{0} := \ket{s} \]
%	\item [Single spin superposition:] Prepare spin at $s$ as $\alpha\ket{\uparrow}_s + \beta\ket{\downarrow}_s \rightarrow$ \[ \ket{\Psi} := \alpha\ket{0} + \beta\ket{s} \]
%	\end{description}
%\end{frame}}
%
%\begin{center}
%	\includeslide{Mathsetup}
%\end{center}
%
%\noindent In short, states as well as operators are constructed by the tensor product, in the latter case involving many identity matrices of dimension 2. There is a direct correspondence of the order of operations and the numbering of spins in the considered system.



\mode<presentation>{
\begin{frame}[t]{Cartesian product of graphs}\label{GraphProduct}
	\begin{exampleblock}{}
		\setlength\abovedisplayskip{-8pt}
		\begin{center}
			$A_{G\times H} = A_G \otimes \text{1}_{\left|V_H\right|} + \text{1}_{\left|V_G\right|} \otimes A_H$
		\end{center}
	\end{exampleblock}

	\begin{columns}[T]
		\begin{column}{0.33\textwidth}
			\centering
   			\includegraphics[width=\textwidth]{Images/graphprod_chain3_square}
		\end{column}
		\uncover<2->{\begin{column}{0.33\textwidth}
			\centering
    		\includegraphics[trim=0 0 0 -10mm, width=\textwidth]{Images/graphprod_chain3_chain2_square}
		\end{column}}
     	\uncover<3->{\begin{column}{0.33\textwidth}
     		\centering
     		\includegraphics[trim=30mm 0 0 0, width=0.9\textwidth]{Images/graphprod_switch_square}
		\end{column}}
	\end{columns}
\end{frame}
}

\begin{center}
	\includeslide{GraphProduct}
\end{center}

\noindent Higher order graphs can be built by using the cartesian product of graphs\cite{Sabidussi1959}. Note that this is not a tensor product, which can be defined for graphs as well. Vertices of the product graph are all ordered pairs of underlying simple graph vertices. The cartesian graph product is therefore commutative. The edge set consists of unordered pairs of unordered vertex pairs in which either the first vertices or the second vertices are connected in one of the original graphs. In other words, if graph G has 4 vertices one would take 4 copies of graph H and connect the vertices in such a way, that these connections form G graphs. 


\section{Perfect State Transfer}
\subsection{PST}
\mode<presentation>{
\begin{frame}{Perfect state transfer}\label{PST}
	\begin{exampleblock}{}
		\setlength\abovedisplayskip{-8pt}
		\begin{center}
			\[ f^N_{r,s}(t) = \bra{r}e^{-\text{i}H t}\ket{s} \mbeq 1 \]
		\end{center}
	\end{exampleblock}

	\begin{columns}[T]
		\begin{column}{0.33\textwidth}
			\centering
			\includegraphics[trim=0 0 0 -5mm, width=\textwidth]{Images/chain2}\\
   			\includegraphics[trim=0 0 0 -35mm, width=\textwidth]{Images/chain3}
		\end{column}
		\begin{column}{0.33\textwidth}
			\centering
   			\includegraphics[trim=0 0 0 -5mm, width=\textwidth]{Images/switch_labeled}
		\end{column}
		\begin{column}{0.33\textwidth}
			\centering
   			\includegraphics[trim=0 0 0 -5mm, width=\textwidth]{Images/switch_square}
		\end{column}
	\end{columns}
\end{frame}
}

\begin{center}
	\includeslide{PST}
\end{center}

\noindent The notion of fidelity stems from the density matrix $\rho_{out}$ associated with the target system state $\Psi_{out}$ averaged over all pure input states $\Psi_{in}$\cite{Bose2003}. It turns out, however, that for the fidelity of state transfer to equal unity, it is sufficient to ensure the absolute of the transition amplitude $f^N_{r,s}$ to be unity. The overall phase in form of the cosine can be neutralized by an overall magnetic field. We will therefore restrict ourselves here to ensuring the unit absolute of the transition amplitude.\par
There are other options to quantify the quality of state transfer such as concurrence or von-Neumann entropy. The fidelity as defined here is the most widely adopted.

\mode<presentation>{
\begin{frame}[t]{Fidelity on product graphs}\label{GraphProductFidelitySummary}
	\begin{exampleblock}{}
		\setlength\abovedisplayskip{-8pt}
		\begin{center}
			$ f^{\left|V_{G\times H}\right|}_{(r,r'),(s,s')}(t) = f^{\left|V_G\right|}_{r,s}(t)\cdot f^{\left|V_H\right|}_{r',s'}(t) $
		\end{center}
	\end{exampleblock}

	\begin{align*}
		\left|f^{\left|V_G\right|}_{r,s}(t)\right| &= 1 \text{ for } t = \tau_G \\ 
		\left|f^{\left|V_H\right|}_{r',s'}(t)\right| &= 1 \text{ for } t = \tau_H \\ 
		\left|f^{\left|V_{G\times H}\right|}_{(r,r'),(s,s')}(t)\right| &= 1 \text{ for } t = \tau_{G\times H}
	\end{align*}

	\begin{exampleblock}{}
		\setlength\abovedisplayskip{-4pt}
		\begin{center}
			$ \text{iff }\frac{\tau_G}{\tau_H} \in \mathbb{Q}$ %\rightarrow t_{G\times H} = LCM(t_G,t_H) $
		\end{center}
	\end{exampleblock}
\end{frame}
}

\begin{center}
	\includeslide{GraphProductFidelitySummary}
\end{center}

\noindent The fidelity on product graphs exhibits a product structure. The proof exploits the additive structure of adjacency matrices of product graphs. One simply expresses the transition amplitude of the product graph in terms of the underlying graphs eigenvectors and eigenvalues. The eigenvectors and eigenvalues of the original graph adjacency matrices times the identity matrix are simply the (tensor) products of each respective operators eigenvectors and eigenvalues. Applying the cartesian product reduction identity 4 times and splitting the sums reveals that the transition amplitude of state transfer on a product graph is the product of the transition amplitudes for state transfer on the underlying graphs.\par
Having a unity transition amplitude requires unit transfer times of underlying graphs to form rational numbers when divided. This is rarely the case. The obvious exclusion is the product of graphs with themselves. In this case, perfect state transfer is automatically achieved in exactly the same time. This means more distance can be covered by connecting qubits in a way so that they resemble the product graph of a simple PST graph with itself.

\subsection{Identifying Graphs with PST}
\mode<presentation>{
\begin{frame}[t]{Identifying PST Graphs}\label{IdentifyPST}
	\begin{exampleblock}{}
		\setlength\abovedisplayskip{-8pt}
		\begin{center}
			\[ e^{-i\, H\, \tau} = P_\pi \]
		\end{center}
	\end{exampleblock}
	
	\begin{center}
		\begin{itemize}
			\item Restriction to single spin subspace
			\item Model qubit sites as vector
			\item PST interchanges vector components
		\end{itemize}

		$\rightarrow$ Test for permutation matrices!
	\end{center}
	
	\uncover<2->{\begin{align*}
		\begin{pmatrix}
			1\\0\\0\\0
		\end{pmatrix}
		\rightarrow
		\begin{pmatrix}
			0\\0\\0\\1
		\end{pmatrix}
		\,\,\, \text{e.g.} \,\,\,\, P_\pi = 
		\begin{pmatrix}
			0 & 0 & 0 & 1\\
			0 & 1 & 0 & 0\\
			0 & 0 & 1 & 0\\
			1 & 0 & 0 & 0\\
		\end{pmatrix}
	\end{align*}}
\end{frame}
}

\begin{center}
	\includeslide{IdentifyPST}
\end{center}

\noindent The identification of PST graphs is easily achieved by testing if the matrix exponential of the corresponding adjacency matrix yields a permutation matrix for some time $\tau$. The time can be found by testing when the transposed matrix exponential times the normal matrix exponential of the adjacency matrix yields the unit matrix. If there is no solution, there is no PST on that graph.



\mode<presentation>{
\begin{frame}[t]{More general Solutions}\label{MoreGeneralPermutations}
	\centering
	\includegraphics[trim=0 0 0 -5mm, width=0.8\textwidth]{Images/chain4_nolabels}
	\vfill

	\begin{columns}[T]
		\begin{column}{0.33\textwidth}
			\centering
			\begin{align*}
	   			\begin{pmatrix}
					0 & 0 & 0 & 1\\
					0 & a & b & 0\\
					0 & c & d & 0\\
					1 & 0 & 0 & 0\\
				\end{pmatrix}
			\end{align*}

			Effect on non-interesting sites irrelevant.
		\end{column}
		\begin{column}{0.33\textwidth}
			\centering
    		\uncover<2->{\begin{align*}
	   			\begin{pmatrix}
					0 & 0 & 0 & -1\\
					0 & a & b & 0\\
					0 & c & d & 0\\
					-1 & 0 & 0 & 0\\
				\end{pmatrix}
			\end{align*}

			Use a phase flip gate at arrival site.}
		\end{column}
     	\begin{column}{0.33\textwidth}
     		\centering
     		\uncover<3->{\begin{align*}
	   			\begin{pmatrix}
					0 & 0 & 0 & e^{i\phi}\\
					0 & a & b & 0\\
					0 & c & d & 0\\
					e^{i\phi} & 0 & 0 & 0\\
				\end{pmatrix}
			\end{align*}

			Use a phase shift gate at arrival site.}
		\end{column}
	\end{columns}
\end{frame}
}

\begin{center}
	\includeslide{MoreGeneralPermutations}
\end{center}

\noindent Permutations in this case aren't confined to matrices with entries only $0$ or $1$. The state might acquire a phase during transit. As long as this phase is known, a simple gate operation at the receiving site returns it to the correct state. In most cases looked at here, only a simple phase flip is required.

\subsection{Examples for Permutations}
\mode<presentation>{
\begin{frame}[t]{Example Permutations}\label{SpinSwitch}
	\begin{columns}[T]
		\begin{column}{0.33\textwidth}
			\centering
   			\includegraphics[trim=0mm 0 0 0mm, width=0.8\textwidth]{Images/chain4p_nolabels} \\
   			\begin{align*}
	   			\begin{pmatrix}
					0 & 0 & 1 & 0\\
					0 & 0 & 0 & 1\\
					1 & 0 & 0 & 0\\
					0 & 1 & 0 & 0\\
				\end{pmatrix}
			\end{align*}
		\end{column}
		\begin{column}{0.33\textwidth}
			\centering
    		\includegraphics[trim=0mm 0 0 0mm, width=0.9\textwidth]{Images/switch_labeled} \\
    		\begin{align*}
	   			\begin{pmatrix}
					1 & 0 & 0 & 0\\
					0 & 0 & 1 & 0\\
					0 & 1 & 0 & 0\\
					0 & 0 & 0 & 1\\
				\end{pmatrix}
			\end{align*}
		\end{column}
		\begin{column}{0.33\textwidth}
			\centering
			\vspace{\baselineskip}
			\vspace{\baselineskip}
    		\includegraphics[trim=0mm 0 0 10mm, width=1.6\textwidth]{Images/skewStarUnity} \\
    		\vspace{\baselineskip}

    		\begin{align*}
 	  			\begin{pmatrix}
				\frac{1}{2} & -\frac{1}{2} & 0 & 0 & -\frac{1}{2} & -\frac{1}{2}\\
				-\frac{1}{2} & \frac{1}{2} & 0 & 0 & -\frac{1}{2} & -\frac{1}{2}\\
				0 & 0 & 0 & -1 & 0 & 0\\
				0 & 0 & -1 & 0 & 0 & 0\\
				-\frac{1}{2} & -\frac{1}{2} & 0 & 0 & \frac{1}{2} & -\frac{1}{2}\\
				-\frac{1}{2} & -\frac{1}{2} & 0 & 0 & -\frac{1}{2} & \frac{1}{2}
				\end{pmatrix}
			\end{align*}
		\end{column}
	\end{columns}
\end{frame}
}

\mode<presentation>{
\begin{frame}{Test for Permutation}\label{PermutationTest}
	\vfill
	\begin{center}
		\begin{itemize}
			\item $P_\pi \cdot P_\pi^T = \text{1}$
			\item Check if $e^{-i\, H\, \tau}\cdot \left[e^{-i\, H\, \tau}\right]^T = 1$ for some $\tau $
			\item If there is no solution, there is no PST on this graph
			\item Otherwise, check if $\tau/2$ leads to a (generalized) permutation
		\end{itemize}
	\end{center}
\end{frame}
}


\section{Contruction}
\subsection{Constructing PST Networks}
\mode<presentation>{
\begin{frame}{Constructing PST Networks}\label{PSTNetConstruction}
	\begin{itemize}
		\item Group Theory \hfill \uncover<2->{\textcolor{problemred}{$\rightarrow$ not enough time}}
		\item Logarithm of $P_\pi$ \hfill \uncover<3->{\textcolor{problemred}{$\rightarrow$ trivial networks}}
		\item Use logarithm of $P_\pi$ eigenvalues \hfill \uncover<4->{\textcolor{problemred}{$\rightarrow$ trivial networks}}
		\item Use spectral decomposition of $P_\pi$ to create corresponding Hamiltonian:\\
			\[ P_\pi = \sum_{\lambda_j} \lambda_j \ket{y_{\lambda_j}}\bra{y_{\lambda_j}} \,\,\, \rightarrow \,\,\, H_l = \frac{1}{\tau}\sum_{\lambda_j} [\text{arg}(\lambda_j) + 2\pi l_{\lambda_j}] \ket{y_{\lambda_j}}\bra{y_{\lambda_j}} \] \\ 
			\uncover<5->{\textcolor{problemred}{$\rightarrow$ trivial networks:} \quad \includegraphics[trim=0mm 0 0 0mm, width=0.4\textwidth]{Images/chain2_nolabels_2isolated}} \\ 
			\cite{Christandl2004}
		\item Model as matrix multiplication \hfill \uncover<6->{\textcolor{problemred}{$\rightarrow$ same problem}}\uncover<7->{, but:\\
			\textcolor{barcolor}{$\rightarrow$ compulsory columns!}}
	\end{itemize}
\end{frame}
}

\begin{center}
	\includeslide{GraphProductFidelitySummary}
\end{center}

\noindent Unfortunately, the mechanism behind why this method works is currently unknown. It was tested with only a few networks and should be treated accordingly.

\subsection{Examples}
\mode<presentation>{
\begin{frame}[t]{Construction Plan}\label{ConstructionPlan}
	\begin{center}
		\includegraphics[trim=0mm 0mm 0mm 0mm, width=0.3\textwidth]{Images/chain4p_nolabels_generaledges}

		\begin{itemize}
			\item 1 input node, 1 output node
			\item Bipartite graph
			\item Model transition from input node to middle column and from middle column to output node as two distinct matrices:\\
			\begin{align*}
	   			\begin{pmatrix}
					c & d
				\end{pmatrix} \cdot 
				\begin{pmatrix}
					a \\ b
				\end{pmatrix} \cdot 1
				\mbeq 1
			\end{align*}
		\end{itemize}
	\end{center}
\end{frame}
}


\mode<presentation>{
\begin{frame}[t]{Solutions}\label{Solutions}
	\begin{center}
		\includegraphics[trim=0mm 0mm 0mm 0mm, width=0.3\textwidth]{Images/chain4p_nolabels_generaledges}		
		\begin{exampleblock}{}
			\setlength\abovedisplayskip{-8pt}
			\begin{center}
				$ac + bd \mbeq 1$
			\end{center}
		\end{exampleblock}		

		\begin{itemize}
			\item $a = c = 0$, $b = d = 1$ (and vice versa): \hfill \includegraphics[trim=0mm 0mm 0mm -20mm, width=0.15\textwidth]{Images/chain4_simple_solution_1}
			\item $a = b = c = d = \frac{1}{\sqrt{2}}$: \hfill \includegraphics[trim=0mm 0mm 0mm -20mm, width=0.15\textwidth]{Images/chain4p_nolabels}
			\item There are other solutions
		\end{itemize}
	\end{center}
\end{frame}
}

\mode<presentation>{
\begin{frame}[t]{Complex Example}\label{ComplexExample}
	\begin{center}
		\begin{columns}[T]
			\begin{column}{0.5\textwidth}
				\centering
   				\includegraphics[trim=0mm 0mm 0mm -5mm, width=0.8\textwidth]{Images/complexexample_weights}
			\end{column}
			\begin{column}{0.5\textwidth}
				\centering
				\vspace{\baselineskip}
   				\begin{itemize}
   					\item 2 input nodes, 2 output nodes
   					\item 2 conditions
   					\item 13 solutions, some parametric
   					\item only a few are symmetric
   				\end{itemize}
			\end{column}
		\end{columns}
		\uncover<2->{\begin{align*}
			\begin{pmatrix}
				y_1 & y_2 & y_3 \\
				z_1 & z_2 & z_3
			\end{pmatrix} 			
			\cdot		 
			\begin{pmatrix}
				a1 & b1 \\
				a2 & b2 \\
				a3 & b3
			\end{pmatrix} 				
			\cdot 
			\begin{pmatrix}
				1 \\
				0
			\end{pmatrix}		
			\mbeq			
			\begin{pmatrix}
				1 \\
				0
			\end{pmatrix}
		\end{align*}
		\begin{align*}
			\begin{pmatrix}
				y_1 & y_2 & y_3 \\
				z_1 & z_2 & z_3
			\end{pmatrix} 
			\cdot					 
			\begin{pmatrix}
				a1 & b1 \\
				a2 & b2 \\
				a3 & b3
			\end{pmatrix} 					
			\cdot 	
			\begin{pmatrix}
				0 \\
				1
			\end{pmatrix}			
			\mbeq				
			\begin{pmatrix}
				0 \\
				1
			\end{pmatrix}
		\end{align*}}
	\end{center}
\end{frame}
}

\mode<presentation>{
\begin{frame}[t]{Complex Solutions}\label{ComplexSolutions}
	\begin{columns}[T]
		\begin{column}{0.33\textwidth}
			\centering
   			\includegraphics[trim=0mm 0mm 0mm -5mm, width=0.8\textwidth]{Images/complexexample_solution_1}
		\end{column}
		\begin{column}{0.33\textwidth}
			\centering
   			\includegraphics[trim=0mm 0mm 0mm -5mm, width=0.8\textwidth]{Images/complexexample_solution_4} \\
		\end{column}
		\begin{column}{0.33\textwidth}
			\centering
   			\includegraphics[trim=0mm 0mm 0mm -5mm, width=0.8\textwidth]{Images/complexexample_solution_3}
		\end{column}
	\end{columns}
\end{frame}
}

\begin{center}
	\includeslide{ComplexSolutions}
\end{center}

\noindent A more complex example for the algorithm yields the above solutions, which all exhibit the desired PST properties.

\mode<presentation>{
\begin{frame}[t]{Missing Solutions}\label{MissingSolutions}
	Some obvious solutions are missing, e.g.:	

	\begin{columns}[T]
		\begin{column}{0.5\textwidth}
			\centering
   			\includegraphics[trim=0mm 0mm 0mm -5mm, width=0.8\textwidth]{Images/complexexample_solution_missing}
		\end{column}
		\begin{column}{0.5\textwidth}
			\vspace{\baselineskip}
			\centering

   			\only<1-1>{
   				\begin{exampleblock}{}
					\setlength\abovedisplayskip{-8pt}
					\begin{center}$e^{-i H \tau}$ with $\tau = \frac{1}{2}$ from $a$ to $x$:
					\end{center}
				\end{exampleblock}
   			\begin{align*}
				\SmallMatrix{
				0 & 0 & 0 & 0 & 0 & -1 & 0 \\
				0 & a & 0 & 0 & b & 0 & c \\
				0 & 0 & 0 & -1 & 0 & 0 & 0 \\
				0 & 0 & -1 & 0 & 0 & 0 & 0 \\
				0 & b & 0 & 0 & a+c & 0 & b \\
				-1 & 0 & 0 & 0 & 0 & 0 & 0 \\
				0 & c & 0 & 0 & b & 0 & a \\
				} 
			\end{align*}} 

			\only<2-2>{\begin{exampleblock}{}
				\setlength\abovedisplayskip{-8pt}
				\begin{center}
					$e^{-i H \tau}$ with $\tau = \frac{1}{\sqrt{2}}$ from $b$ to $y$:
				\end{center}
			\end{exampleblock}
   			\begin{align*}
				\SmallMatrix{
 				d & 0 & e & e & 0 & d-1 & 0 \\
			 	0 & 0 & 0 & 0 & 0 & 0 & -1 \\
				e & 0 & d & d-1 & 0 & e & 0 \\
				e & 0 & d-1 & d & 0 & e & 0 \\
				0 & 0 & 0 & 0 & -1 & 0 & 0 \\
				d-1 & 0 & e & e & 0 & d & 0 \\
				0 & -1 & 0 & 0 & 0 & 0 & 0 
				} 
			\end{align*}}
		\end{column}
	\end{columns}
\end{frame}
}


\begin{center}
	\includeslide{MissingSolutions}
\end{center}

\noindent Some solutions are not found among the set of parameters. This is mostly due to missing symmetry or differing times for PST in parts of the graph.


\section{Roadmap}
\mode<presentation>{
\begin{frame}[t]{Roadmap}\label{Roadmap}
	\vfill
	\begin{itemize}
		\item Extend method to graphs with multiple PSTs at different times
		\uncover<2->{\item Numerical methods for faster calculation}
		\uncover<3->{\item PST on higher spin subspaces}
		\uncover<4->{\item Include local potentials and switching}
		\uncover<5->{\item \textbf{Provide a proof}}
	\end{itemize}
\end{frame}
}

\begin{center}
	\includeslide{Roadmap}
\end{center}

\noindent All these findings hint at a mechanism that can be used to derive an adjacency matrix with certain properties, such that its single-spin subgraph automatically provides a spin network exhibiting the desired properties. A very early example of what this might look like is the flattened graph of a two-link hypercube, or in other words, the fourfold graph product of a 2-qubit chain with itself. Flattened out, this graph can be arranged in columns such that each column contains only qubits with an equal number of forward and backward edges connecting qubits in adjacent columns only. The qubits in each respective column can be renormalized\cite{Christandl2005}. The resulting couplings turn out to be the perfect couplings as described earlier. This reduction from a 16-qubit network to a 5-qubit network might be possible analytically and provide a whole class of PST capable networks with locally changing couplings.

\bibliography{refs}
\bibliographystyle{unsrt}

\end{document}
